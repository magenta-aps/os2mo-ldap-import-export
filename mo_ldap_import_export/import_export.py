# SPDX-FileCopyrightText: Magenta ApS <https://magenta.dk>
# SPDX-License-Identifier: MPL-2.0
import json
from collections.abc import Awaitable
from collections.abc import Callable
from contextlib import ExitStack
from functools import wraps
from typing import Any
from typing import TypeVar
from uuid import UUID
from uuid import uuid4

import structlog
from fastapi.encoders import jsonable_encoder
from fastramqpi.ramqp.depends import handle_exclusively_decorator
from ldap3 import Connection
from more_itertools import one
from more_itertools import only
from structlog.contextvars import bound_contextvars

from mo_ldap_import_export import models

from .autogenerated_graphql_client.input_types import EmployeeFilter
from .autogenerated_graphql_client.input_types import ITSystemFilter
from .autogenerated_graphql_client.input_types import ITUserFilter
from .config import LDAP2MOMapping
from .config import Settings
from .config import get_required_attributes
from .converters import LdapConverter
from .customer_specific_checks import ExportChecks
from .dataloaders import DN
from .dataloaders import DataLoader
from .dataloaders import NoGoodLDAPAccountFound
from .exceptions import DryRunException
from .exceptions import IncorrectMapping
from .exceptions import InvalidCPR
from .exceptions import NoObjectsReturnedException
from .exceptions import RequeueException
from .exceptions import SkipObject
from .ldap import apply_discriminator
from .ldap import filter_dns
from .ldap_classes import LdapObject
from .moapi import Verb
from .moapi import get_primary_engagement
from .models import Address
from .models import Class
from .models import Employee
from .models import Engagement
from .models import ITSystem
from .models import ITUser
from .models import MOBase
from .models import OrganisationUnit
from .models import Termination
from .models import Validity
from .types import EmployeeUUID
from .types import OrgUnitUUID
from .utils import ensure_list
from .utils import is_list
from .utils import mo_today

logger = structlog.stdlib.get_logger()


T = TypeVar("T", covariant=True)


def with_exitstack(
    func: Callable[..., Awaitable[T]],
) -> Callable[..., Awaitable[T]]:
    """Inject an exit-stack into decorated function.

    Args:
        func: The function to inject the exit-stack into.

    Returns:
        Decorated function that takes the exit-stack as an argument.
    """

    @wraps(func)
    async def inner(*args: Any, **kwargs: Any) -> Any:
        with ExitStack() as exit_stack:
            return await func(*args, **kwargs, exit_stack=exit_stack)

    return inner


class SyncTool:
    def __init__(
        self,
        dataloader: DataLoader,
        converter: LdapConverter,
        export_checks: ExportChecks,
        settings: Settings,
        ldap_connection: Connection,
    ) -> None:
        self.dataloader: DataLoader = dataloader
        self.converter: LdapConverter = converter
        self.export_checks: ExportChecks = export_checks
        self.settings: Settings = settings
        self.ldap_connection: Connection = ldap_connection

    async def perform_export_checks(self, employee_uuid: UUID) -> None:
        """
        Perform a number of customer-specific checks. Raising IgnoreChanges() if a
        check fails
        """

        # Check that the employee has an it-user with user_key = it_user_to_check
        await self.export_checks.check_it_user(
            employee_uuid,
            self.settings.it_user_to_check,
        )

    async def render_ldap2mo(
        self, uuid: EmployeeUUID, dn: DN | None
    ) -> dict[str, list[Any]]:
        await self.perform_export_checks(uuid)

        mo2ldap_template = self.settings.conversion_mapping.mo2ldap
        assert mo2ldap_template is not None
        template = self.converter.environment.from_string(mo2ldap_template)
        result = await template.render_async({"uuid": uuid, "dn": dn})
        logger.debug("Rendered jinja template", uuid=uuid, dn=dn, result=result)
        parsed = json.loads(result)
        logger.debug(
            "Parsed jinja template", uuid=uuid, dn=dn, result=result, parsed=parsed
        )
        assert isinstance(parsed, dict)
        assert all(isinstance(key, str) for key in parsed)
        # Convert None's to empty lists to avoid writing "None" in LDAP
        # Whenever a None is templated out we empty the value in LDAP
        parsed = {key: [] if value is None else value for key, value in parsed.items()}
        # TODO: force users to configure as list instead of implicitly
        # converting (very confusing).
        # assert all(isinstance(value, list) for value in parsed.values())
        return {key: ensure_list(value) for key, value in parsed.items()}

    async def ensure_ituser_link(self, uuid: EmployeeUUID, dn: DN) -> None:
        # Check if we even dare create a DN
        raw_it_system_uuid = await self.dataloader.moapi.get_ldap_it_system_uuid()
        if raw_it_system_uuid is None:
            return None
        it_system_uuid = UUID(raw_it_system_uuid)

        # If the LDAP ITSystem exists, we want to create a binding to our newly
        # generated (and created) DN, such that it can be correlated in the future.
        #
        # NOTE: This may not be executed if the program crashes after creating the LDAP
        #       account, but before creating this ituser link.
        #       Thus the current code is not robust and may fail at any time.
        #       The appropriate solution here is either to ensure that the LDAP account
        #       and the ituser link are created atomically or to introduce a multi-stage
        #       commit solution to the integration.
        #       One practical solution may be to entirely eliminate the need for these
        #       ituser links by allocating a field in LDAP for the MO UUID and using
        #       that field to link MO and LDAP accounts together.
        #       An alternative solution may involve writing a temporary dummy value to
        #       LDAP on the initial create which can be detected later to ensure that
        #       creation is completed even if the program crashes at an inopportune
        #       time. - The risk of this approach is that we have bad values in LDAP,
        #       which may be synchronized by other listeners on LDAP, and thus have
        #       unforseen consequences.
        logger.info("No ITUser found, ensuring one exists to correlate with DN")
        # Get its unique ldap uuid
        # TODO: Get rid of this code and operate on EntityUUIDs thoughout
        unique_uuid = await self.dataloader.ldapapi.get_ldap_unique_ldap_uuid(dn)
        logger.info("LDAP UUID found for DN", dn=dn, ldap_uuid=unique_uuid)
        result = await self.dataloader.moapi.graphql_client.read_ituser_uuid(
            ITUserFilter(
                user_keys=[str(unique_uuid)],
                itsystem=ITSystemFilter(uuids=[it_system_uuid]),
                employee=EmployeeFilter(uuids=[uuid]),
            )
        )
        # If the link already exists, do nothing
        if len(result.objects) != 0:
            logger.info("Not creating link as it already exists")
            return
        logger.info("Creating link as it is missing")
        # If the link does not exist, create it
        it_user = ITUser(
            user_key=str(unique_uuid),
            itsystem=it_system_uuid,
            person=uuid,
            validity=Validity(start=mo_today(), end=None),
            org_unit=None,
        )
        await self.dataloader.moapi.create_ituser(it_user)

    async def may_create_user_given_orgunit_location(self, uuid: EmployeeUUID) -> bool:
        create_user_trees = set(self.settings.create_user_trees)
        # Empty set, means nothing to check, which means we will create
        if not create_user_trees:
            logger.debug("create_user_trees not configured, allowing create")
            return True

        primary_engagement_uuid = await get_primary_engagement(
            self.dataloader.moapi.graphql_client, uuid
        )
        if primary_engagement_uuid is None:
            logger.info(
                "create_user_trees configured, but no primary engagement, skipping"
            )
            return False

        fetched_engagement = await self.dataloader.moapi.load_mo_engagement(
            primary_engagement_uuid, end=None
        )
        if fetched_engagement is None:
            logger.info("create_user_trees engagement is not current or future")
            return False

        org_unit_uuid = fetched_engagement.org_unit
        if org_unit_uuid in create_user_trees:
            return True

        # Converting ancestors to a set, as we do not care which ancestor is found
        ancestors = set(
            await self.dataloader.moapi.get_ancestors(OrgUnitUUID(org_unit_uuid))
        )
        # If any ancestor is overlapping with the create_user_trees UUIDs we match
        overlap = create_user_trees.intersection(ancestors)
        return bool(overlap)

    @with_exitstack
    async def listen_to_changes_in_employees(
        self,
        uuid: EmployeeUUID,
        exit_stack: ExitStack,
        dry_run: bool = False,
    ) -> dict[str, list[Any]]:
        """Synchronize employee data from MO to LDAP.

        Args:
            uuid: UUID of the changed employee.
            exit_stack: The injected exit-stack.
        """
        exit_stack.enter_context(bound_contextvars(uuid=str(uuid)))
        logger.info("Registered change in an employee")

        mo2ldap_template = self.settings.conversion_mapping.mo2ldap
        if not mo2ldap_template:
            logger.info("listen_to_changes_in_employees called without mapping")
            return {}

        try:
            best_dn = await self.dataloader._find_best_dn(uuid)
        except NoGoodLDAPAccountFound:
            return {}
        except NoObjectsReturnedException:
            # TODO: Distinguish invalid events and deleted using registration history
            logger.exception(
                "Could not find MO employee, likely deleted or invalid event"
            )
            return {}

        # No DN set, means we are creating
        if best_dn is None:
            # If dry-running we do not want to generate real DNs in LDAP
            is_ok = await self.may_create_user_given_orgunit_location(uuid)
            if not is_ok:
                logger.info("Primary engagement OU outside create_user_trees, skipping")
                return {}

        exit_stack.enter_context(bound_contextvars(dn=best_dn))
        try:
            ldap_desired_state = await self.render_ldap2mo(uuid, best_dn)
        except SkipObject:
            logger.info("Not writing to LDAP as skip was requested")
            return {}

        if not ldap_desired_state:
            logger.info("Not writing to LDAP as changeset is empty")
            return {}

        create = False
        if best_dn is None:
            create = True
            common_name = (
                only(ldap_desired_state["cn"]) if "cn" in ldap_desired_state else None
            )
            # TODO: When we are creating a user we should make sure we have a reference
            #       to it, the ituser-link in the below attempts to create this link,
            #       however there is no guarantee that the program does not crash between
            #       these two lines, and as such it does *NOT* work as a robust link.
            #       This has however been an issue since the introduction of the
            #       integration so it has always been broken, and we have always risked
            #       leaking LDAP accounts.
            #       The good solution is to somehow link the LDAP account to MO with
            #       values set during its creation, ensuring we can find them, even if
            #       we crash immediately after the creation of the account.
            best_dn = await self.dataloader.make_mo_employee_dn(uuid, common_name)

        current_dn = await self.dataloader.ldapapi.ensure_ldap_object(
            best_dn,
            ldap_desired_state,
            self.settings.ldap_object_class,
            create,
            dry_run,
        )
        if dry_run:
            raise DryRunException("No changes", best_dn, details={})
        await self.ensure_ituser_link(uuid, current_dn)
        return ldap_desired_state

    async def fetch_uuid_object(
        self, uuid: UUID, mo_class: type[MOBase]
    ) -> MOBase | None:
        # This type is not handled by this function
        assert not issubclass(mo_class, Termination)

        if issubclass(mo_class, Address):
            return await self.dataloader.moapi.load_mo_address(
                uuid, current_objects_only=False
            )
        if issubclass(mo_class, Engagement):
            return await self.dataloader.moapi.load_mo_engagement(
                uuid, start=None, end=None
            )
        if issubclass(mo_class, ITUser):
            return await self.dataloader.moapi.load_mo_it_user(
                uuid, current_objects_only=False
            )
        if issubclass(mo_class, ITSystem):
            return await self.dataloader.moapi.load_mo_it_system(
                uuid, current_objects_only=False
            )
        if issubclass(mo_class, Class):
            return await self.dataloader.moapi.load_mo_class(
                uuid, current_objects_only=False
            )
        if issubclass(mo_class, Employee):
            return await self.dataloader.moapi.load_mo_employee(
                uuid, current_objects_only=False
            )
        if issubclass(mo_class, OrganisationUnit):
            return await self.dataloader.moapi.load_mo_org_unit(
                uuid, current_objects_only=False
            )
        raise AssertionError(f"Unknown mo_class: {mo_class}")

    def get_mapping(self, json_key: str) -> LDAP2MOMapping:
        assert self.settings.conversion_mapping.ldap_to_mo is not None
        try:
            return self.settings.conversion_mapping.ldap_to_mo[json_key]
        except KeyError as error:  # pragma: no cover
            raise IncorrectMapping(
                f"Missing '{json_key}' in mapping 'ldap_to_mo'"
            ) from error

    @with_exitstack
    async def import_single_user(
        self, ldap_object: LdapObject, exit_stack: ExitStack, dry_run: bool = False
    ) -> None:
        """Imports a single user from LDAP into MO.

        Args:
            ldap_object:
                The LDAP object that triggered our event.

                Must already have the required attributes specified in:
                `settings.conversion_mapping.ldap_to_mo[ALL].ldap_attributes`.
            exit_stack: The injected exit-stack.
            dry_run: If True, simulates the import without making changes.
        """
        exit_stack.enter_context(bound_contextvars(dn=ldap_object.dn))

        logger.info("Importing user")

        if not self.settings.conversion_mapping.ldap_to_mo:
            logger.info("import_single_user called without mapping")
            return

        attributes_to_load = set(ldap_object.dict().keys()) - {"dn"}

        # Get the employee's UUID (if they exists)
        try:
            employee_uuid = await self.dataloader.find_mo_employee_uuid(ldap_object)
        except InvalidCPR:  # pragma: no cover
            if self.settings.ldap_to_mo_legacy_skip_invalid_cpr_accounts:
                return
            raise
        if employee_uuid:
            # If we found an employee UUID, we want to use that to find all DNs
            ldap_objects_list = await self.dataloader.find_mo_employee_dn(
                uuid=employee_uuid, attributes=attributes_to_load
            )
        else:  # We did not find an employee UUID
            ldap_to_mo = self.settings.conversion_mapping.ldap_to_mo
            assert ldap_to_mo is not None
            # Check if we wish to create the employee or not
            if "Employee" not in ldap_to_mo:  # pragma: no cover
                logger.info(
                    "Employee not found in MO, and no ldap_to_mo Employee mapping"
                )
                return
            employee_mapping = ldap_to_mo["Employee"]

            create_employee = employee_mapping.import_to_mo == "true"
            if not create_employee:
                # If we do not want to create the employee and it does not exist, there
                # is no more to be done, as we cannot create dependent resources with no
                # employee to attach them to.
                logger.info("Employee not found in MO, and not configured to create it")
                return
            logger.info("Employee not found, but configured to create it")

            # As we wish to create an employee, we need to generate an UUID for it
            employee_uuid = EmployeeUUID(uuid4())
            logger.info(
                "Employee not found in MO, generated UUID", employee_uuid=employee_uuid
            )
            # At this point employee_uuid is always set

            # We want to create our employee using the best possible LDAP account.
            # By default, we will use the account that was provided to us in the event.
            ldap_objects_list = [ldap_object]

            # However we may be able to find other accounts using the CPR number on the
            # event triggered account, by searching for the CPR number in all of LDAP.
            # Note however, that this will only succeed if there is a CPR number field.
            cpr_number = self.dataloader.ldapapi.ldap_object2cpr(ldap_object)
            # Only attempt to load accounts if we have a CPR number to do so with
            if cpr_number:
                ldap_objects_list = await self.dataloader.ldapapi.cpr2dns(
                    cpr_number, attributes_to_load
                )

        # At this point 'employee_uuid' is an UUID that may or may not be in MO
        # At this point 'ldap_objects_list' is a list of LDAP objects

        # We always want to synchronize from the best LDAP account, instead of just
        # synchronizing from the last LDAP account that has been touched.
        # Thus we process the list of DNs found for the user to pick the best one.
        ldap_objects_list = await filter_dns(self.settings, ldap_objects_list)
        best_object = await apply_discriminator(
            self.settings,
            self.ldap_connection,
            self.dataloader.moapi,
            employee_uuid,
            ldap_objects_list,
        )
        # If no good LDAP account was found, we do not want to synchronize at all
        if best_object is None:
            logger.info(
                "Aborting synchronization, as no good LDAP account was found",
                dns={obj.dn for obj in ldap_objects_list},
                employee_uuid=employee_uuid,
            )
            return

        # At this point, we have the best possible DN for the user, and their employee UUID
        if ldap_object.dn != best_object.dn:
            logger.info(
                "Found better DN for employee",
                best_dn=best_object.dn,
                dns={obj.dn for obj in ldap_objects_list},
                employee_uuid=employee_uuid,
            )
            # We refetch the ldap_object with the same attributes as the incoming one
            ldap_object = await self.dataloader.ldapapi.get_object_by_dn(
                best_object.dn, attributes=attributes_to_load
            )
            exit_stack.enter_context(bound_contextvars(dn=best_object.dn))

        json_keys = list(self.settings.conversion_mapping.ldap_to_mo.keys())
        json_keys = [
            json_key
            for json_key in json_keys
            if self.settings.conversion_mapping.ldap_to_mo[json_key].import_to_mo
            != "false"
        ]
        logger.info("Import to MO filtered", json_keys=json_keys)

        template_context = {
            "employee_uuid": str(employee_uuid),
        }

        # The template author should make sure to define objects in order, so
        # dependencies exist before their dependent objects.
        for json_key in json_keys:
            await self.import_single_entity(
                self.get_mapping(json_key),
                ldap_object,
                template_context,
                dry_run=dry_run,
            )

    @with_exitstack
    async def import_single_object_class(
        self, object_class: str, ldap_object: LdapObject, exit_stack: ExitStack
    ) -> None:
        """Imports a single object class from LDAP into MO.

        Args:
            object_class: The LDAP object class we want to import.
            ldap_object:
                The LDAP object that triggered our event.

                Must already have the required attributes specified in:
                `settings.conversion_mapping.ldap_to_mo_any[ALL].ldap_attributes`.
        """
        exit_stack.enter_context(
            bound_contextvars(object_class=object_class, dn=ldap_object.dn)
        )
        logger.info("Importing object class")
        mappings = self.settings.conversion_mapping.ldap_to_mo_any[object_class]
        for mapping in mappings:
            await self.import_single_entity(
                mapping, ldap_object, template_context={}, dry_run=False
            )

    @handle_exclusively_decorator(
        key=lambda self, mapping, ldap_object, template_context, dry_run: ldap_object.dn
    )
    async def import_single_entity(
        self,
        mapping: LDAP2MOMapping,
        ldap_object: LdapObject,
        template_context: dict[str, Any],
        dry_run: bool,
    ) -> None:
        """Import a single entity from an LDAP object.

        Args:
            mapping: The mapping configuration for this entity.
            ldap_object:
                The LDAP object to import.

                Must already have the required attributes specified in:
                `mapping.ldap_attributes`.
            template_context: Context variables for Jinja2 templates.
            dry_run: If True, simulates the import without making changes.
        """
        dn = ldap_object.dn
        logger.info("Loading object", mo_class=mapping.as_mo_class(), dn=dn)

        # Ensure that the object has the required attributes
        required_attributes = set(mapping.ldap_attributes) - {"dn"}
        # Note: We rely on Pydantic's .dict() to give us the attributes on the object.
        # This includes fields defined on the model and extra fields.
        available_attributes = set(ldap_object.dict().keys())
        missing_attributes = required_attributes - available_attributes
        assert (
            not missing_attributes
        ), f"ldap_object missing required attributes: {missing_attributes}"

        loaded_object = ldap_object

        logger.info(
            "Loaded object",
            mo_class=mapping.as_mo_class(),
            dn=dn,
            loaded_object=loaded_object,
        )

        def convert_value(value: Any) -> Any:
            if not is_list(value):
                return value
            # If the value is a single element list, return the contents
            if len(value) == 1:
                return one(value)
            # Otherwise simply return the list
            return value

        ldap_dict = {
            key: convert_value(value) for key, value in loaded_object.dict().items()
        }
        context = {"ldap": ldap_dict, **template_context}

        try:
            # Pydantic validator ensures that uuid is set here
            uuid_str = await self.converter.render_template(
                "uuid", mapping.uuid, context
            )
        except SkipObject:
            logger.info("Skipping object", field="uuid", dn=dn)
            return

        uuid = UUID(uuid_str) if uuid_str else None

        mo_class = mapping.as_mo_class()
        mo_object = await self.fetch_uuid_object(uuid, mo_class) if uuid else None

        # Handle creates
        if mo_object is None:
            try:
                converted_object = await self._create_converted_object(
                    mapping, context, mo_class
                )
            except SkipObject:
                logger.info("Skipping object", dn=dn)
                return

            logger.info(
                "Importing object", verb=Verb.CREATE, obj=converted_object, dn=dn
            )
            if dry_run:
                raise DryRunException(
                    "Would have uploaded changes to MO",
                    dn,
                    details={
                        "verb": str(Verb.CREATE),
                        "obj": jsonable_encoder(converted_object, exclude={"mo_class"}),
                    },
                )
            await self.dataloader.moapi.create(converted_object)
            return

        # Handle termination
        if mapping.terminate:
            try:
                terminate_template = mapping.terminate
                terminate = await self.converter.render_template(
                    "terminate", terminate_template, context
                )
            except SkipObject:  # pragma: no cover
                logger.info("Skipping object", field="terminate", dn=dn)
                return

            if terminate:
                # Asked to terminate, but uuid template did not return an uuid, i.e.
                # there was no object to actually terminate, so we just skip it.
                if not uuid:  # pragma: no cover
                    message = "Unable to terminate without UUID"
                    logger.info(message)
                    return
                termination = Termination(mo_class=mo_class, at=terminate, uuid=uuid)
                logger.info(
                    "Importing object", verb=Verb.TERMINATE, obj=termination, dn=dn
                )
                if dry_run:
                    raise DryRunException(
                        "Would have uploaded changes to MO",
                        dn,
                        details={
                            "verb": str(Verb.TERMINATE),
                            "obj": jsonable_encoder(termination, exclude={"mo_class"}),
                        },
                    )
                await self.dataloader.moapi.terminate(termination)
                return

        # Handle updates
        try:
            converted_object = await self._create_converted_object(
                mapping, context, mo_class
            )
        except SkipObject:  # pragma: no cover
            logger.info("Skipping object", dn=dn)
            return

        mo_attributes = set(mapping.get_fields().keys())

        # Convert our objects to dicts
        mo_object_dict_to_upload = mo_object.dict()
        # Only the *intersection* of attribute names from
        # mo_object_dict_to_upload and converted_mo_object_dict are used.
        converted_mo_object_dict = converted_object.dict()

        # Update the existing MO object with the converted values
        # NOTE: UUID cannot be updated as it is used to decide what we update
        # NOTE: objectClass is removed as it is an LDAP implemenation detail
        # TODO: Why do we not update validity???
        mo_attributes = mo_attributes - {"validity", "uuid", "objectClass"}
        # Only copy over keys that exist in both sets
        mo_attributes = mo_attributes & converted_mo_object_dict.keys()

        update_values = {
            key: converted_mo_object_dict[key]
            for key in mo_attributes
            # Only include values that actually need to be updated
            if mo_object_dict_to_upload[key] != converted_mo_object_dict[key]
            # And don't include the sentinel UNSET value as a literal value
            and converted_mo_object_dict[key] != models.UNSET
        }
        # If an object is identical to the one already there, it does not need
        # to be uploaded.
        if not update_values:
            logger.info("Converted object is identical to existing object, skipping")
            return

        logger.info(
            "Setting values on upload dict",
            uuid=mo_object_dict_to_upload["uuid"],
            values=update_values,
            old_values={key: mo_object_dict_to_upload[key] for key in update_values},
        )

        mo_object_dict_to_upload.update(update_values)
        obj = mo_class(**mo_object_dict_to_upload)

        logger.info("Importing object", verb=Verb.EDIT, obj=obj, dn=dn)
        if dry_run:
            raise DryRunException(
                "Would have uploaded changes to MO",
                dn,
                details={
                    "verb": str(Verb.EDIT),
                    "obj": jsonable_encoder(obj, exclude={"mo_class"}),
                },
            )

        await self.dataloader.moapi.edit(obj)

    async def _create_converted_object(
        self, mapping: LDAP2MOMapping, context: dict[str, Any], mo_class: type[MOBase]
    ) -> MOBase:
        # TODO: asyncio.gather this for future dataloader bulking
        mo_dict = {
            mo_field_name: await self.converter.render_template(
                mo_field_name, template_str, context
            )
            for mo_field_name, template_str in mapping.get_fields().items()
        }

        required_attributes = get_required_attributes(mo_class)

        # Load our validity default, if it is not set
        if "validity" in required_attributes:
            assert "validity" not in mo_dict, "validity disallowed in ldap2mo mappings"
            mo_dict["validity"] = Validity(
                start=mo_today(),
                end=None,
            ).dict()

        # If any required attributes are missing
        missing_attributes = required_attributes - set(mo_dict.keys())
        # TODO: Restructure this so rejection happens during parsing?
        if missing_attributes:  # pragma: no cover
            logger.info(
                "Missing attributes in dict to model conversion",
                mo_dict=mo_dict,
                mo_class=mo_class,
                missing_attributes=missing_attributes,
            )
            raise ValueError("Missing attributes in dict to model conversion")

        # Remove empty values
        mo_dict = {key: value for key, value in mo_dict.items() if value}
        # If any required attributes are missing
        missing_attributes = required_attributes - set(mo_dict.keys())
        if missing_attributes:  # pragma: no cover
            logger.error(
                "Missing values in LDAP to synchronize",
                suggestion=(
                    "If missing values are expected, consider: skip_if_none. "
                    "If skip_if_none is used, the field is probably whitespace only."
                ),
                mo_dict=mo_dict,
                mo_class=mo_class,
                missing_attributes=missing_attributes,
            )
            raise RequeueException("Missing values in LDAP to synchronize")

        return mo_class(**mo_dict)
